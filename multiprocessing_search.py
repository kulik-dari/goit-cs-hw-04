#!/usr/bin/env python3
"""
–ë–∞–≥–∞—Ç–æ–ø—Ä–æ—Ü–µ—Å–æ—Ä–Ω–∞ –≤–µ—Ä—Å—ñ—è –ø—Ä–æ–≥—Ä–∞–º–∏ –ø–æ—à—É–∫—É –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ —É —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö —Ñ–∞–π–ª–∞—Ö.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –º–æ–¥—É–ª—å multiprocessing –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—ñ–≤.
"""

import os
import time
import multiprocessing
from pathlib import Path
from typing import List, Dict, Tuple
from collections import defaultdict
import re

def search_keywords_in_file(filepath: str, keywords: List[str]) -> Tuple[str, Dict[str, bool]]:
    """
    –®—É–∫–∞—î –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –≤ –æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—ñ (—Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è multiprocessing)
    
    Args:
        filepath: –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
        keywords: –°–ø–∏—Å–æ–∫ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –¥–ª—è –ø–æ—à—É–∫—É
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂: (—à–ª—è—Ö_–¥–æ_—Ñ–∞–π–ª—É, {–∫–ª—é—á–æ–≤–µ_—Å–ª–æ–≤–æ: –∑–Ω–∞–π–¥–µ–Ω–æ})
    """
    found_keywords = {}
    
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as file:
            content = file.read().lower()
            
            for keyword in keywords:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ñ –≤–∏—Ä–∞–∑–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É —Å–ª—ñ–≤
                pattern = r'\b' + re.escape(keyword.lower()) + r'\b'
                found_keywords[keyword] = bool(re.search(pattern, content))
                
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ñ–∞–π–ª—É {filepath}: {e}")
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏
        found_keywords = {keyword: False for keyword in keywords}
    
    return filepath, found_keywords

def worker_process(file_chunk: List[str], keywords: List[str], 
                  process_id: int, result_queue: multiprocessing.Queue):
    """
    –†–æ–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —á–∞—Å—Ç–∏–Ω–∏ —Ñ–∞–π–ª—ñ–≤
    
    Args:
        file_chunk: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —Ü–∏–º –ø—Ä–æ—Ü–µ—Å–æ–º
        keywords: –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ—à—É–∫—É
        process_id: –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –ø—Ä–æ—Ü–µ—Å—É
        result_queue: –ß–µ—Ä–≥–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    """
    try:
        local_results = defaultdict(list)
        files_processed = 0
        error_count = 0
        
        print(f"üöÄ –ü—Ä–æ—Ü–µ—Å {process_id}: –ø–æ—á–∞–≤ –æ–±—Ä–æ–±–∫—É {len(file_chunk)} —Ñ–∞–π–ª—ñ–≤")
        
        for filepath in file_chunk:
            try:
                file_path, found_keywords = search_keywords_in_file(filepath, keywords)
                
                # –î–æ–¥–∞—î–º–æ —Ñ–∞–π–ª –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ–≥–æ –∫–ª—é—á–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞
                for keyword, found in found_keywords.items():
                    if found:
                        local_results[keyword].append(file_path)
                
                files_processed += 1
                
                # –ü–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –≤–∏–≤–æ–¥–∏–º–æ –ø—Ä–æ–≥—Ä–µ—Å
                if files_processed % 5 == 0:
                    print(f"üîç –ü—Ä–æ—Ü–µ—Å {process_id}: –æ–±—Ä–æ–±–ª–µ–Ω–æ {files_processed}/{len(file_chunk)} —Ñ–∞–π–ª—ñ–≤")
                    
            except Exception as e:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—ñ {process_id} –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ {filepath}: {e}")
                error_count += 1
        
        # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —á–µ—Ä–µ–∑ —á–µ—Ä–≥—É
        result_data = {
            'process_id': process_id,
            'results': dict(local_results),
            'files_processed': files_processed,
            'errors': error_count
        }
        
        result_queue.put(result_data)
        print(f"‚úÖ –ü—Ä–æ—Ü–µ—Å {process_id}: –∑–∞–≤–µ—Ä—à–µ–Ω–æ –æ–±—Ä–æ–±–∫—É {files_processed} —Ñ–∞–π–ª—ñ–≤, –ø–æ–º–∏–ª–æ–∫: {error_count}")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—ñ {process_id}: {e}")
        # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ–º–∏–ª–∫—É
        result_queue.put({
            'process_id': process_id,
            'results': {},
            'files_processed': 0,
            'errors': 1,
            'critical_error': str(e)
        })

class MultiprocessingFileSearcher:
    """–ö–ª–∞—Å –¥–ª—è –±–∞–≥–∞—Ç–æ–ø—Ä–æ—Ü–µ—Å–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ —É —Ñ–∞–π–ª–∞—Ö"""
    
    def __init__(self, num_processes: int = None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ—à—É–∫–∞—á–∞
        
        Args:
            num_processes: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—ñ–≤ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º - –∫—ñ–ª—å–∫—ñ—Å—Ç—å CPU)
        """
        if num_processes is None:
            self.num_processes = multiprocessing.cpu_count()
        else:
            self.num_processes = max(1, num_processes)
        
        self.total_files = 0
        self.processed_files = 0
        self.error_count = 0
    
    def split_files_into_chunks(self, file_list: List[str]) -> List[List[str]]:
        """
        –†–æ–∑–¥—ñ–ª—è—î —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª—ñ–≤ –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ –¥–ª—è –ø—Ä–æ—Ü–µ—Å—ñ–≤
        
        Args:
            file_list: –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö —Ñ–∞–π–ª—ñ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞—Å—Ç–∏–Ω —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—É
        """
        chunk_size = len(file_list) // self.num_processes
        remainder = len(file_list) % self.num_processes
        
        chunks = []
        start = 0
        
        for i in range(self.num_processes):
            # –†–æ–∑–ø–æ–¥—ñ–ª—è—î–º–æ –∑–∞–ª–∏—à–æ–∫ –º—ñ–∂ –ø–µ—Ä—à–∏–º–∏ –ø—Ä–æ—Ü–µ—Å–∞–º–∏
            end = start + chunk_size + (1 if i < remainder else 0)
            
            if start < len(file_list):
                chunks.append(file_list[start:end])
            else:
                chunks.append([])  # –ü–æ—Ä–æ–∂–Ω—ñ–π —á–∞–Ω–∫, —è–∫—â–æ —Ñ–∞–π–ª—ñ–≤ –º–µ–Ω—à–µ –Ω—ñ–∂ –ø—Ä–æ—Ü–µ—Å—ñ–≤
            
            start = end
        
        return chunks
    
    def search_files(self, directory: str, keywords: List[str], 
                    file_pattern: str = "*.txt") -> Dict[str, List[str]]:
        """
        –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –±–∞–≥–∞—Ç–æ–ø—Ä–æ—Ü–µ—Å–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É
        
        Args:
            directory: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ —Ñ–∞–π–ª–∞–º–∏
            keywords: –°–ø–∏—Å–æ–∫ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –¥–ª—è –ø–æ—à—É–∫—É
            file_pattern: –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ—à—É–∫—É —Ñ–∞–π–ª—ñ–≤
            
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {–∫–ª—é—á–æ–≤–µ_—Å–ª–æ–≤–æ: [—Å–ø–∏—Å–æ–∫_—Ñ–∞–π–ª—ñ–≤]}
        """
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –±–∞–≥–∞—Ç–æ–ø—Ä–æ—Ü–µ—Å–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É...")
        print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è: {directory}")
        print(f"üîç –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞: {', '.join(keywords)}")
        print(f"‚öôÔ∏è  –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—ñ–≤: {self.num_processes}")
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ —Ñ–∞–π–ª–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
        directory_path = Path(directory)
        if not directory_path.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è {directory} –Ω–µ —ñ—Å–Ω—É—î")
        
        file_list = list(directory_path.glob(file_pattern))
        file_paths = [str(f) for f in file_list]
        
        if not file_paths:
            print(f"‚ö†Ô∏è  –§–∞–π–ª–∏ –∑–∞ —à–∞–±–ª–æ–Ω–æ–º {file_pattern} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ —É {directory}")
            return {}
        
        self.total_files = len(file_paths)
        print(f"üìÑ –ó–Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª—ñ–≤: {self.total_files}")
        
        # –°–∫–∏–¥–∞—î–º–æ –ª—ñ—á–∏–ª—å–Ω–∏–∫–∏
        self.processed_files = 0
        self.error_count = 0
        
        # –ó–∞—Å—ñ–∫–∞—î–º–æ —á–∞—Å
        start_time = time.time()
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ —Ñ–∞–π–ª–∏ –º—ñ–∂ –ø—Ä–æ—Ü–µ—Å–∞–º–∏
        file_chunks = self.split_files_into_chunks(file_paths)
        
        print(f"üìä –†–æ–∑–ø–æ–¥—ñ–ª —Ñ–∞–π–ª—ñ–≤ –ø–æ –ø—Ä–æ—Ü–µ—Å–∞—Ö:")
        for i, chunk in enumerate(file_chunks):
            print(f"   –ü—Ä–æ—Ü–µ—Å {i+1}: {len(chunk)} —Ñ–∞–π–ª—ñ–≤")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —á–µ—Ä–≥—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        result_queue = multiprocessing.Queue()
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —ñ –∑–∞–ø—É—Å–∫–∞—î–º–æ –ø—Ä–æ—Ü–µ—Å–∏
        processes = []
        for i, chunk in enumerate(file_chunks):
            if chunk:  # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ—Ü–µ—Å —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —î —Ñ–∞–π–ª–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
                process = multiprocessing.Process(
                    target=worker_process,
                    args=(chunk, keywords, i + 1, result_queue)
                )
                processes.append(process)
                process.start()
        
        # –ó–±–∏—Ä–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ —á–µ—Ä–≥–∏
        final_results = defaultdict(list)
        processes_completed = 0
        
        while processes_completed < len(processes):
            try:
                # –û—á—ñ–∫—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑ —Ç–∞–π–º–∞—É—Ç–æ–º
                result_data = result_queue.get(timeout=30)
                
                process_id = result_data['process_id']
                process_results = result_data['results']
                files_processed = result_data['files_processed']
                errors = result_data['errors']
                
                # –û–±'—î–¥–Ω—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
                for keyword, file_list in process_results.items():
                    final_results[keyword].extend(file_list)
                
                self.processed_files += files_processed
                self.error_count += errors
                
                processes_completed += 1
                
                if 'critical_error' in result_data:
                    print(f"‚ö†Ô∏è  –ü—Ä–æ—Ü–µ—Å {process_id} –∑–∞–≤–µ—Ä—à–∏–≤—Å—è –∑ –∫—Ä–∏—Ç–∏—á–Ω–æ—é –ø–æ–º–∏–ª–∫–æ—é: {result_data['critical_error']}")
                
            except Exception as e:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {e}")
                break
        
        # –û—á—ñ–∫—É—î–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤
        for process in processes:
            process.join(timeout=10)
            if process.is_alive():
                print(f"‚ö†Ô∏è  –ü—Ä–∏–º—É—Å–æ–≤–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø—Ä–æ—Ü–µ—Å—É {process.pid}")
                process.terminate()
                process.join()
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è:")
        print(f"   ‚è±Ô∏è  –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   üìÅ –û–±—Ä–æ–±–ª–µ–Ω–æ —Ñ–∞–π–ª—ñ–≤: {self.processed_files}/{self.total_files}")
        print(f"   ‚ùå –ü–æ–º–∏–ª–æ–∫: {self.error_count}")
        if execution_time > 0:
            print(f"   üöÄ –®–≤–∏–¥–∫—ñ—Å—Ç—å: {self.processed_files/execution_time:.1f} —Ñ–∞–π–ª—ñ–≤/—Å–µ–∫")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —É –∑–≤–∏—á–∞–π–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫
        results = dict(final_results)
        
        print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É:")
        for keyword in keywords:
            files_found = len(results.get(keyword, []))
            print(f"   '{keyword}': –∑–Ω–∞–π–¥–µ–Ω–æ —É {files_found} —Ñ–∞–π–ª–∞—Ö")
        
        return results

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Ä–æ–±–æ—Ç–∏ –±–∞–≥–∞—Ç–æ–ø—Ä–æ—Ü–µ—Å–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫–∞—á–∞"""
    
    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    search_directory = "test_files"
    keywords_to_search = ["python", "algorithm", "data", "function", "programming"]
    num_processes = multiprocessing.cpu_count()
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤
    if not Path(search_directory).exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è {search_directory} –Ω–µ —ñ—Å–Ω—É—î!")
        print("üí° –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å file_generator.py –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤")
        return
    
    try:
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—à—É–∫–∞—á
        searcher = MultiprocessingFileSearcher(num_processes=num_processes)
        
        # –í–∏–∫–æ–Ω—É—î–º–æ –ø–æ—à—É–∫
        results = searcher.search_files(
            directory=search_directory,
            keywords=keywords_to_search
        )
        
        # –î–µ—Ç–∞–ª—å–Ω–∏–π –≤–∏–≤—ñ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        print(f"\n" + "="*60)
        print("üìã –î–ï–¢–ê–õ–¨–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ü–û–®–£–ö–£")
        print("="*60)
        
        for keyword, files in results.items():
            print(f"\nüîç –ö–ª—é—á–æ–≤–µ —Å–ª–æ–≤–æ: '{keyword}'")
            if files:
                print(f"   –ó–Ω–∞–π–¥–µ–Ω–æ —É {len(files)} —Ñ–∞–π–ª–∞—Ö:")
                for file_path in sorted(files):
                    filename = Path(file_path).name
                    print(f"     ‚Ä¢ {filename}")
            else:
                print("   ‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –∂–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—ñ")
        
        # –ü—ñ–¥—Å—É–º–æ–∫
        total_matches = sum(len(files) for files in results.values())
        print(f"\nüìä –ó–∞–≥–∞–ª—å–Ω–∏–π –ø—ñ–¥—Å—É–º–æ–∫:")
        print(f"   üéØ –í—Å—å–æ–≥–æ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω—å: {total_matches}")
        print(f"   üìù –ö–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤: {len(keywords_to_search)}")
        print(f"   ‚öôÔ∏è  –ü—Ä–æ—Ü–µ—Å—ñ–≤ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ: {num_processes}")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")

if __name__ == "__main__":
    main()
